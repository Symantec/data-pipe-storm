run.location = local
source.type = kafka


#source Kakfa Point
sourceZooKeeperURL=localhost:2181
inputTopic = source-ga


#source RabbitMq points , Currently only handles only one shard count, overriden in code
rabbitmq.shard.count=1
rabbitmq.queueName0=Naren_Byte
rabbitmq.host0=localhost
rabbitmq.port0=5672
rabbitmq.username0=guest
rabbitmq.password0=guest
rabbitmq.prefetchCount0=100
rabbitmq.ha.hosts0=localhost
rabbitmq.requeueOnFail0=true
rabbitmq.virtualhost0=/


#destination
destinationKafkaURL=localhost:9092,localhost:9091
outputTopic = destination-bytes

#not used sourceKafkaURL, destination ZooKeeperURL only for testing 
destinationZooKeeperURL=localhost:2181
sourceKafkaURL=localhost:9092

#encoding  kafka.serializer.DefaultEncoder for bytes and kafka.serializer.StringEncoder for String 
serializerEncodingValue = kafka.serializer.StringEncoder
# Field Name , bytes for bytes , str for StringSchema
partitionFieldName = str

# raw for RawScheme (bytes) , string for StringScheme
schemeType = string

#Mostly static values # keep topologyName and StreamName unique every time.
topologyName = datapipe
streamName= datapipe
requiredAcks = -1
spoutParallelCount=1
boltParallelCount=1
metricsParallelCount=1
topology.workers=1
topology.spout.max.batch.size=20
topology.message.timeout.secs=30
topology.max.spout.pending=100
message.send.max.retries=0